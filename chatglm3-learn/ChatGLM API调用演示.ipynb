{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd7b04dc-3f41-40fb-8f0c-efa547405ead",
   "metadata": {},
   "source": [
    "# ChatGLMå¤§æ¨¡å‹å¼€å‘"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "å¼€å‘è°ƒè¯•è¯´æ˜ï¼šæœ¬åœ°GPUä¸è¶³ï¼Œæ²¡æœ‰éƒ¨ç½²ChatGLM,é‡‡ç”¨ä¸‹é¢ä¸¤ç§æ–¹å¼è¿›è¡Œå¼€å‘è°ƒè¯•\n",
    "1.ç›´æ¥åœ¨äº‘æœåŠ¡å™¨ä¸­è¿è¡ŒJupyterè¿›è¡Œå¼€å‘æµ‹è¯•ã€‚\n",
    "2.æœ¬åœ°Pycharmè¿æ¥è¿œç¨‹æœåŠ¡å™¨,å®ç°è¿œç¨‹æœåŠ¡å™¨æœ¬åœ°è°ƒè¯•ã€‚"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "fc6577da-e4f0-4e0e-b7bd-84294e40dc58",
   "metadata": {},
   "source": [
    "## 1. ChatGLM3-6Bæ¨¡å‹APIè°ƒç”¨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22003a6-7bbe-4a2f-9b15-c9b57b744ad6",
   "metadata": {},
   "source": [
    "æ­¥éª¤1ï¼š å¯¼å…¥ç›¸å…³çš„åº“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d52d8a5-a5b4-4c64-b9a9-7d6b39ad766a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f03fb3-9ac5-499e-a43b-eb0dce9fa2ba",
   "metadata": {},
   "source": [
    "æ­¥éª¤2ï¼šåŠ è½½tokenizerï¼Œé¦–æ¬¡åŠ è½½éœ€è¦çš„æ—¶é—´è¾ƒé•¿\n",
    "ä½¿ç”¨ AutoTokenizer.from_pretrained æ–¹æ³•ï¼ŒåŠ è½½é¢„è®­ç»ƒçš„tokenizer \"THUDM/chatglm3-6b\" ã€‚\n",
    "trust_remote_code=True è¡¨ç¤ºä¿¡ä»»è¿œç¨‹ä»£ç ã€‚\n",
    "\n",
    "ä½¿ç”¨Hugging Faceä¸Šå¼€æºçš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œä¸ä¾èµ–äºchatglm3å·¥ç¨‹æºä»£ç "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31124224-467f-4782-892e-77480e40fc74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"THUDM/chatglm3-6b\",\n",
    "trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdf7c57-a78b-4385-8bad-3263ee4a7a3a",
   "metadata": {},
   "source": [
    "æ­¥éª¤3ï¼šåŠ è½½é¢„è®­ç»ƒæ¨¡å‹\n",
    "ï¼ˆè¿™é‡Œæ˜¯ç›´æ¥ä½¿ç”¨Hugging Faceçš„æ¨¡å‹åº“ä¸­å¼€æºçš„é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œå¼€å‘æµ‹è¯•ï¼‰\n",
    "ä½¿ç”¨ AutoModel.from_pretrained æ–¹æ³•ï¼ŒåŠ è½½é¢„è®­ç»ƒçš„æ¨¡å‹ \"THUDM/chatglm3-6b\" åˆ°CUDAè®¾\n",
    "å¤‡ä¸Šã€‚ trust_remote_code=True è¡¨ç¤ºä¿¡ä»»è¿œç¨‹ä»£ç ï¼ˆå¦‚æœæœ‰ï¼‰ï¼Œ device='cuda' è¡¨ç¤ºå°†æ¨¡å‹åŠ è½½åˆ°CUDAè®¾å¤‡ä¸Šä»¥ä¾¿ä½¿ç”¨GPUåŠ é€Ÿ\n",
    "\n",
    "è¦æ³¨æ„çš„æ˜¯ï¼Œæ ¹æ®æ˜¾å¡æ˜¾å­˜çš„ä¸åŒï¼Œéœ€è¦è€ƒè™‘åŠ è½½ä¸åŒç²¾åº¦çš„æ¨¡å‹ã€‚13GBæ˜¾å­˜ä»¥ä¸Šçš„æ˜¾å¡å¯ä»¥ç›´æ¥æŒ‰ç…§ä¸Šè¿°ä»£ç åŠ è½½å…¨ç²¾åº¦çš„æ¨¡å‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7f0f70-b8ed-4b4a-807f-94a280c220b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModel.from_pretrained(\"THUDM/chatglm3-6b\", trust_remote_code=True,device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "217b4875-7eec-419c-a98c-91d174ca0505",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008466005325317383,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Loading checkpoint shards",
       "rate": null,
       "total": 7,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25f99cdbc22844b7b81abc53f5745fe6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModel.from_pretrained(\"THUDM/chatglm3-6b\",trust_remote_code=True).quantize(8).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "818a4006-ccf3-4eac-ae6f-47fc1a6f334f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00846552848815918,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Loading checkpoint shards",
       "rate": null,
       "total": 7,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d5f4ea28da8414081a830194a0d30ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'round_up' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mAutoModel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mTHUDM/chatglm3-6b\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43mtrust_remote_code\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mquantize\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m4\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mcuda()\n",
      "File \u001B[0;32m~/.cache/huggingface/modules/transformers_modules/THUDM/chatglm3-6b/e46a14881eae613281abbd266ee918e93a56018f/modeling_chatglm.py:1205\u001B[0m, in \u001B[0;36mChatGLMForConditionalGeneration.quantize\u001B[0;34m(self, bits, empty_init, device, **kwargs)\u001B[0m\n\u001B[1;32m   1201\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mquantized \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m   1203\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mquantization_bit \u001B[38;5;241m=\u001B[39m bits\n\u001B[0;32m-> 1205\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransformer\u001B[38;5;241m.\u001B[39mencoder \u001B[38;5;241m=\u001B[39m \u001B[43mquantize\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransformer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbits\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mempty_init\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mempty_init\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1206\u001B[0m \u001B[43m                                    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1207\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[0;32m~/.cache/huggingface/modules/transformers_modules/THUDM/chatglm3-6b/e46a14881eae613281abbd266ee918e93a56018f/quantization.py:155\u001B[0m, in \u001B[0;36mquantize\u001B[0;34m(model, weight_bit_width, empty_init, device)\u001B[0m\n\u001B[1;32m    153\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Replace fp16 linear with quantized linear\"\"\"\u001B[39;00m\n\u001B[1;32m    154\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m model\u001B[38;5;241m.\u001B[39mlayers:\n\u001B[0;32m--> 155\u001B[0m     layer\u001B[38;5;241m.\u001B[39mself_attention\u001B[38;5;241m.\u001B[39mquery_key_value \u001B[38;5;241m=\u001B[39m \u001B[43mQuantizedLinear\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    156\u001B[0m \u001B[43m        \u001B[49m\u001B[43mweight_bit_width\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mweight_bit_width\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    157\u001B[0m \u001B[43m        \u001B[49m\u001B[43mweight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlayer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mself_attention\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mquery_key_value\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcuda\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcurrent_device\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    158\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbias\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlayer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mself_attention\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mquery_key_value\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    159\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlayer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mself_attention\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mquery_key_value\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    160\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlayer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mself_attention\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mquery_key_value\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    161\u001B[0m \u001B[43m        \u001B[49m\u001B[43mempty_init\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mempty_init\u001B[49m\n\u001B[1;32m    162\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    163\u001B[0m     layer\u001B[38;5;241m.\u001B[39mself_attention\u001B[38;5;241m.\u001B[39mdense \u001B[38;5;241m=\u001B[39m QuantizedLinear(\n\u001B[1;32m    164\u001B[0m         weight_bit_width\u001B[38;5;241m=\u001B[39mweight_bit_width,\n\u001B[1;32m    165\u001B[0m         weight\u001B[38;5;241m=\u001B[39mlayer\u001B[38;5;241m.\u001B[39mself_attention\u001B[38;5;241m.\u001B[39mdense\u001B[38;5;241m.\u001B[39mweight\u001B[38;5;241m.\u001B[39mto(torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mcurrent_device()),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    169\u001B[0m         empty_init\u001B[38;5;241m=\u001B[39mempty_init\n\u001B[1;32m    170\u001B[0m     )\n\u001B[1;32m    171\u001B[0m     layer\u001B[38;5;241m.\u001B[39mmlp\u001B[38;5;241m.\u001B[39mdense_h_to_4h \u001B[38;5;241m=\u001B[39m QuantizedLinear(\n\u001B[1;32m    172\u001B[0m         weight_bit_width\u001B[38;5;241m=\u001B[39mweight_bit_width,\n\u001B[1;32m    173\u001B[0m         weight\u001B[38;5;241m=\u001B[39mlayer\u001B[38;5;241m.\u001B[39mmlp\u001B[38;5;241m.\u001B[39mdense_h_to_4h\u001B[38;5;241m.\u001B[39mweight\u001B[38;5;241m.\u001B[39mto(torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mcurrent_device()),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    177\u001B[0m         empty_init\u001B[38;5;241m=\u001B[39mempty_init\n\u001B[1;32m    178\u001B[0m     )\n",
      "File \u001B[0;32m~/.cache/huggingface/modules/transformers_modules/THUDM/chatglm3-6b/e46a14881eae613281abbd266ee918e93a56018f/quantization.py:139\u001B[0m, in \u001B[0;36mQuantizedLinear.__init__\u001B[0;34m(self, weight_bit_width, weight, bias, device, dtype, empty_init, *args, **kwargs)\u001B[0m\n\u001B[1;32m    137\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweight \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mround(weight \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweight_scale[:, \u001B[38;5;28;01mNone\u001B[39;00m])\u001B[38;5;241m.\u001B[39mto(torch\u001B[38;5;241m.\u001B[39mint8)\n\u001B[1;32m    138\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m weight_bit_width \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m4\u001B[39m:\n\u001B[0;32m--> 139\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweight \u001B[38;5;241m=\u001B[39m \u001B[43mcompress_int4_weight\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    141\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweight \u001B[38;5;241m=\u001B[39m Parameter(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweight\u001B[38;5;241m.\u001B[39mto(device), requires_grad\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m    142\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweight_scale \u001B[38;5;241m=\u001B[39m Parameter(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweight_scale\u001B[38;5;241m.\u001B[39mto(device), requires_grad\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "File \u001B[0;32m~/.cache/huggingface/modules/transformers_modules/THUDM/chatglm3-6b/e46a14881eae613281abbd266ee918e93a56018f/quantization.py:76\u001B[0m, in \u001B[0;36mcompress_int4_weight\u001B[0;34m(weight)\u001B[0m\n\u001B[1;32m     73\u001B[0m stream \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mcurrent_stream()\n\u001B[1;32m     75\u001B[0m gridDim \u001B[38;5;241m=\u001B[39m (n, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m---> 76\u001B[0m blockDim \u001B[38;5;241m=\u001B[39m (\u001B[38;5;28mmin\u001B[39m(\u001B[43mround_up\u001B[49m(m, \u001B[38;5;241m32\u001B[39m), \u001B[38;5;241m1024\u001B[39m), \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     78\u001B[0m kernels\u001B[38;5;241m.\u001B[39mint4WeightCompression(\n\u001B[1;32m     79\u001B[0m     gridDim,\n\u001B[1;32m     80\u001B[0m     blockDim,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     83\u001B[0m     [ctypes\u001B[38;5;241m.\u001B[39mc_void_p(weight\u001B[38;5;241m.\u001B[39mdata_ptr()), ctypes\u001B[38;5;241m.\u001B[39mc_void_p(out\u001B[38;5;241m.\u001B[39mdata_ptr()), ctypes\u001B[38;5;241m.\u001B[39mc_int32(n), ctypes\u001B[38;5;241m.\u001B[39mc_int32(m)],\n\u001B[1;32m     84\u001B[0m )\n\u001B[1;32m     85\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m out\n",
      "\u001B[0;31mNameError\u001B[0m: name 'round_up' is not defined"
     ]
    }
   ],
   "source": [
    "model = AutoModel.from_pretrained(\"THUDM/chatglm3-6b\",trust_remote_code=True).quantize(4).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130ff1fa-e6de-4fec-8075-f71c8ca131a7",
   "metadata": {},
   "source": [
    "æ­¥éª¤4ï¼šå®ä¾‹åŒ–æ¨¡å‹\n",
    "æ¥ä¸‹æ¥åˆ™éœ€è¦å¯¹æ¨¡å‹è¿›è¡Œå®ä¾‹åŒ–æ“ä½œï¼Œå¹¶ä¸”è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8b47ab3-b65a-4299-b622-12299ac67f10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c7dac1-eca5-4ed5-a853-89698a024b71",
   "metadata": {},
   "source": [
    "æ­¥éª¤5ï¼šè°ƒç”¨æ¨¡å‹å¹¶è·å–ç»“æœ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61cdb9f1-6c47-410c-9aa6-538fd81e717f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä½ å¥½ğŸ‘‹ï¼æˆ‘æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹ ChatGLM3-6Bï¼Œå¾ˆé«˜å…´è§åˆ°ä½ ï¼Œæ¬¢è¿é—®æˆ‘ä»»ä½•é—®é¢˜ã€‚\n"
     ]
    }
   ],
   "source": [
    "response, history = model.chat(tokenizer, \"ä½ å¥½\", history=[])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6225401c-9223-4aa7-955d-ae613d12b52d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'user', 'content': 'ä½ å¥½'}, {'role': 'assistant', 'metadata': '', 'content': 'ä½ å¥½ğŸ‘‹ï¼æˆ‘æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹ ChatGLM3-6Bï¼Œå¾ˆé«˜å…´è§åˆ°ä½ ï¼Œæ¬¢è¿é—®æˆ‘ä»»ä½•é—®é¢˜ã€‚'}]\n"
     ]
    }
   ],
   "source": [
    "print(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3219d9ba-2766-4f7a-9fea-4bf0d521cd11",
   "metadata": {},
   "source": [
    "å¦‚æœæœ‰å¤šå¼  GPUï¼Œä½†æ˜¯æ¯å¼  GPU çš„æ˜¾å­˜å¤§å°éƒ½ä¸è¶³ä»¥å®¹çº³å®Œæ•´çš„æ¨¡å‹ï¼Œé‚£ä¹ˆå¯ä»¥å°†æ¨¡å‹åˆ‡åˆ†åœ¨å¤šå¼ GPUä¸Šã€‚é¦–å…ˆå®‰è£… accelerate: pip install accelerateï¼Œ\n",
    "ç„¶åé€šè¿‡å¦‚ä¸‹æ–¹æ³•åŠ è½½æ¨¡å‹ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707e2149-8995-4cbb-a34f-994350e4659a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_model_on_gpus\n",
    "model = load_model_on_gpus(\"THUDM/chatglm3-6b\", num_gpus=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff16b83a-0fe0-4a5a-9977-75644ff3478e",
   "metadata": {},
   "source": [
    "## 2. OpenAIé£æ ¼ä»£ç è°ƒç”¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a59993-785f-4b6a-ae1e-9a8bdeba75cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ba6b59-32c6-455d-819c-93f74b9af2db",
   "metadata": {},
   "source": [
    "OpenAIé£æ ¼ä»£ç è°ƒç”¨ï¼Œé¦–å…ˆå¯åŠ¨ python openai_api.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc3f809e-72c3-4ad3-b66a-f8bfccf0ed72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## OpenAIé£æ ¼ä»£ç è°ƒç”¨ï¼Œé¦–å…ˆå¯åŠ¨ python openai_api.py\n",
    "\n",
    "# ä½¿ç”¨curlå‘½ä»¤æµ‹è¯•è¿”å›\n",
    "# curl -X POST \"http://127.0.0.1:8000/v1/chat/completions\" \\\n",
    "# -H \"Content-Type: application/json\" \\\n",
    "# -d \"{\\\"model\\\": \\\"chatglm3-6b\\\", \\\"messages\\\": [{\\\"role\\\": \\\"system\\\", \\\"content\\\": \\\"You are ChatGLM3, a large language model trained by Zhipu.AI. Follow the user's instructions carefully. Respond using markdown.\\\"}, {\\\"role\\\": \\\"user\\\", \\\"content\\\": \\\"ä½ å¥½ï¼Œç»™æˆ‘è®²ä¸€ä¸ªæ•…äº‹ï¼Œå¤§æ¦‚100å­—\\\"}], \\\"stream\\\": false, \\\"max_tokens\\\": 100, \\\"temperature\\\": 0.8, \\\"top_p\\\": 0.8}\"\n",
    "\n",
    "# ä½¿ç”¨Pythonä»£ç æµ‹è¿”å›\n",
    "import requests\n",
    "import json\n",
    "\n",
    "base_url = \"http://127.0.0.1:8000\" # æœ¬åœ°éƒ¨ç½²çš„åœ°å€,æˆ–è€…ä½¿ç”¨ä½ è®¿é—®æ¨¡å‹çš„APIåœ°å€\n",
    "\n",
    "def create_chat_completion(model, messages):\n",
    "    data = {\n",
    "        \"model\": model, # æ¨¡å‹åç§°\n",
    "        \"messages\": messages, # ä¼šè¯å†å²\n",
    "        \"max_tokens\": 100, # æœ€å¤šç”Ÿæˆå­—æ•°\n",
    "        \"temperature\": 0.8, # æ¸©åº¦\n",
    "        \"top_p\": 0.8, # é‡‡æ ·æ¦‚ç‡\n",
    "    }\n",
    "\n",
    "    response = requests.post(f\"{base_url}/v1/chat/completions\", json=data)\n",
    "    decoded_line = response.json()\n",
    "    content = decoded_line.get(\"choices\", [{}])[0].get(\"message\", \"\").get(\"content\", \"\")\n",
    "    return content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a839e69c-90de-45f2-8671-f5f8b28da100",
   "metadata": {},
   "source": [
    "ä»£ç è°ƒç”¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d64ccf47-50c3-49e1-a61f-26be68dfa4bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chat_messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are ChatGLM3, a large language model trained by Zhipu.AI. Follow the user's instructions carefully. Respond using markdown.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"ä½ å¥½ï¼Œç»™æˆ‘è®²ä¸€ä¸ªæ•…äº‹ï¼Œå¤§æ¦‚100å­—\"\n",
    "        }\n",
    "    ]\n",
    "content = create_chat_completion(\"chatglm3-6b\", chat_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75494686-5f0b-417d-9e5b-9ccd668b012f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ä»å‰æœ‰ä¸ªå«å°æ˜çš„å°ç”·å­©ï¼Œä»–éå¸¸å–œæ¬¢çœ‹åŠ¨ç”»ç‰‡ã€‚æœ‰ä¸€å¤©ï¼Œä»–åœ¨ç”µè§†ä¸Šçœ‹åˆ°ä¸€åˆ™å…³äºç¥å¥‡ä¸–ç•Œçš„å¹¿å‘Šï¼Œäºæ˜¯æ¿€åŠ¨åœ°å‘Šè¯‰äº†ä»–çš„å¦ˆå¦ˆã€‚å¦ˆå¦ˆå¸¦ä»–å»äº†ä¸€å®¶å›¾ä¹¦é¦†ï¼Œ whereä»–ä»¬å€Ÿäº†è®¸å¤šå…³äºé­”æ³•å’Œå¥‡å¹»çš„ä¹¦ç±ã€‚å°æ˜åœ¨é˜…è¯»è¿™äº›ä¹¦ç±æ—¶ï¼Œå‘ç°äº†ä¸€ä¸ªåä¸ºâ€œå°é£ä¾ â€çš„è§’è‰²ï¼Œä»–å†³å®šè¦æˆä¸ºä¸€ä¸ªå‹‡æ•¢çš„å®‡èˆªå‘˜ï¼Œæ¢ç´¢æœªçŸ¥çš„æ˜Ÿçƒã€‚ä»æ­¤ä»¥åï¼Œå°æ˜å¸¸å¸¸æƒ³è±¡è‡ªå·±æ˜¯ä¸€ä¸ªå‹‡æ•¢çš„å®‡èˆªå‘˜ï¼Œåœ¨å¤ªç©ºä¸­\n"
     ]
    }
   ],
   "source": [
    "print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a920bdba-5a49-4751-828a-e7939ad35d18",
   "metadata": {},
   "source": [
    "## 3. function callingåŠŸèƒ½"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcff716-77b2-4e03-87c9-1c6513ea201f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.1 è·å–å¤©æ°”APIæ¼”ç¤º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4ca048b-8bdb-40d1-8f97-33d9ddc6844f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#open_weather_key = os.getenv(\"OPENWEATHER_API_KEY\")\n",
    "open_weather_key = \"c6748580ef08742adf7bd05d79dd8e5d\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d262e220-95b5-40d1-a33b-b15b4b65d44e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "def get_weather(loc):\n",
    "    \"\"\"\n",
    "    æŸ¥è¯¢å³æ—¶å¤©æ°”å‡½æ•°\n",
    "    :param loc: å¿…è¦å‚æ•°ï¼Œå­—ç¬¦ä¸²ç±»å‹ï¼Œç”¨äºè¡¨ç¤ºæŸ¥è¯¢å¤©æ°”çš„å…·ä½“åŸå¸‚åç§°ï¼Œ\\\n",
    "    æ³¨æ„ï¼Œä¸­å›½çš„åŸå¸‚éœ€è¦ç”¨å¯¹åº”åŸå¸‚çš„è‹±æ–‡åç§°ä»£æ›¿ï¼Œä¾‹å¦‚å¦‚æœéœ€è¦æŸ¥è¯¢åŒ—äº¬å¸‚å¤©æ°”ï¼Œåˆ™locå‚æ•°éœ€è¦è¾“å…¥'Beijing'ï¼›\n",
    "    :returnï¼šOpenWeather APIæŸ¥è¯¢å³æ—¶å¤©æ°”çš„ç»“æœï¼Œå…·ä½“URLè¯·æ±‚åœ°å€ä¸ºï¼šhttps://api.openweathermap.org/data/2.5/weather\\\n",
    "    è¿”å›ç»“æœå¯¹è±¡ç±»å‹ä¸ºè§£æä¹‹åçš„JSONæ ¼å¼å¯¹è±¡ï¼Œå¹¶ç”¨å­—ç¬¦ä¸²å½¢å¼è¿›è¡Œè¡¨ç¤ºï¼Œå…¶ä¸­åŒ…å«äº†å…¨éƒ¨é‡è¦çš„å¤©æ°”ä¿¡æ¯\n",
    "    \"\"\"\n",
    "    # Step 1.æ„å»ºè¯·æ±‚\n",
    "    url = \"https://api.openweathermap.org/data/2.5/weather\"\n",
    "\n",
    "    # Step 2.è®¾ç½®æŸ¥è¯¢å‚æ•°\n",
    "    params = {\n",
    "        \"q\": loc,               \n",
    "        \"appid\": open_weather_key,    # è¾“å…¥API key\n",
    "        \"units\": \"metric\",            # ä½¿ç”¨æ‘„æ°åº¦è€Œä¸æ˜¯åæ°åº¦\n",
    "        \"lang\":\"zh_cn\"                # è¾“å‡ºè¯­è¨€ä¸ºç®€ä½“ä¸­æ–‡\n",
    "    }\n",
    "\n",
    "    # Step 3.å‘é€GETè¯·æ±‚\n",
    "    response = requests.get(url, params=params)\n",
    "    \n",
    "    # Step 4.è§£æå“åº”\n",
    "    data = response.json()\n",
    "    return json.dumps(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab3da98f-714e-4ced-9cd8-5488447fe592",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data=get_weather(\"BeiJing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "044fdefd-ca1e-4342-b9ef-f9d2ce7651f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"coord\": {\"lon\": 116.3972, \"lat\": 39.9075}, \"weather\": [{\"id\": 801, \"main\": \"Clouds\", \"description\": \"\\\\u6674\\\\uff0c\\\\u5c11\\\\u4e91\", \"icon\": \"02d\"}], \"base\": \"stations\", \"main\": {\"temp\": 15.94, \"feels_like\": 14.09, \"temp_min\": 15.94, \"temp_max\": 15.94, \"pressure\": 1011, \"humidity\": 19, \"sea_level\": 1011, \"grnd_level\": 1005}, \"visibility\": 10000, \"wind\": {\"speed\": 4.98, \"deg\": 299, \"gust\": 8.94}, \"clouds\": {\"all\": 12}, \"dt\": 1700633608, \"sys\": {\"type\": 1, \"id\": 9609, \"country\": \"CN\", \"sunrise\": 1700607993, \"sunset\": 1700643269}, \"timezone\": 28800, \"id\": 1816670, \"name\": \"Beijing\", \"cod\": 200}'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec45df0-77ec-4062-b657-fab26055bc8c",
   "metadata": {},
   "source": [
    "### 3.2 ç›´æ¥è·Ÿå¤§æ¨¡å‹é—®å¤©æ°”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "431154f5-7e16-4d4e-ab26-54a4f8b7f2c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008507251739501953,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Loading checkpoint shards",
       "rate": null,
       "total": 7,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b86de086f1934820b0237879b900c826",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##æµ‹è¯•æ¨¡å‹\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"THUDM/chatglm3-6b\",\n",
    "trust_remote_code=True)\n",
    "\n",
    "model = AutoModel.from_pretrained(\"THUDM/chatglm3-6b\",trust_remote_code=True).quantize(8).cuda()\n",
    "\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5557b95c-872b-41e4-981b-5638a7c31515",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä½ å¥½ï¼ä½œä¸ºä¸€ä¸ªäººå·¥æ™ºèƒ½åŠ©æ‰‹ï¼Œæˆ‘æ— æ³•å®æ—¶è·å–åŒ—äº¬çš„æœ€æ–°å¤©æ°”ä¿¡æ¯ã€‚ä½†ä½ å¯ä»¥æŸ¥çœ‹å¤©æ°”é¢„æŠ¥æˆ–ä½¿ç”¨å¤©æ°”åº”ç”¨æ¥äº†è§£å½“å‰çš„åŒ—äº¬å¤©æ°”ã€‚\n"
     ]
    }
   ],
   "source": [
    "## æµ‹è¯•æ¨¡å‹è°ƒç”¨\n",
    "response, history = model.chat(tokenizer, \"ä½ å¥½ï¼ŒåŒ—äº¬å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ\", history=[])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a1dd35-dafa-4d03-8ab6-87adc341918b",
   "metadata": {},
   "source": [
    "### 3.3 ä¸€æ­¥ä¸€æ­¥æ¼”ç¤ºfunctionè°ƒç”¨æµç¨‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa6b9009-9af4-4f0d-9fbd-9f66c8e613d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## å®šä¹‰function å‡½æ•°\n",
    "weather_api_spec = [\n",
    "    {\n",
    "        'name': 'get_weather',\n",
    "        'description': 'æŸ¥è¯¢å³æ—¶å¤©æ°”å‡½æ•°ï¼Œæ ¹æ®è¾“å…¥çš„åŸå¸‚åç§°ï¼ŒæŸ¥è¯¢å¯¹åº”åŸå¸‚çš„å®æ—¶å¤©æ°”',\n",
    "        'parameters': {\n",
    "            'type': 'object',\n",
    "            'properties': {\n",
    "                'loc': {\n",
    "                    'description': \"åŸå¸‚åç§°ï¼Œæ³¨æ„ï¼Œä¸­å›½çš„åŸå¸‚éœ€è¦ç”¨å¯¹åº”åŸå¸‚çš„è‹±æ–‡åç§°ä»£æ›¿ï¼Œä¾‹å¦‚å¦‚æœéœ€è¦æŸ¥è¯¢åŒ—äº¬å¸‚å¤©æ°”ï¼Œåˆ™locå‚æ•°éœ€è¦è¾“å…¥'Beijing'\",\n",
    "                    'type': 'string',\n",
    "                    'required': True\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "51f8ef19-e0dc-4306-a8db-8ec60ae3628c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## äº›systemè§’è‰²çš„promptä»¥åŠæ·»åŠ tools\n",
    "system_info = {\"role\": \"system\", \n",
    "               \"content\": \"Answer the following questions as best as you can. You have access to the following tools:\", \n",
    "               \"tools\": weather_api_spec}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "93949f2d-76d3-4290-804c-1585a703b2fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'get_weather', 'parameters': {'loc': 'Beijing'}}\n",
      "==============\n",
      "[{'role': 'system', 'content': 'Answer the following questions as best as you can. You have access to the following tools:', 'tools': [{'name': 'get_weather', 'description': 'æŸ¥è¯¢å³æ—¶å¤©æ°”å‡½æ•°ï¼Œæ ¹æ®è¾“å…¥çš„åŸå¸‚åç§°ï¼ŒæŸ¥è¯¢å¯¹åº”åŸå¸‚çš„å®æ—¶å¤©æ°”', 'parameters': {'type': 'object', 'properties': {'loc': {'description': \"åŸå¸‚åç§°ï¼Œæ³¨æ„ï¼Œä¸­å›½çš„åŸå¸‚éœ€è¦ç”¨å¯¹åº”åŸå¸‚çš„è‹±æ–‡åç§°ä»£æ›¿ï¼Œä¾‹å¦‚å¦‚æœéœ€è¦æŸ¥è¯¢åŒ—äº¬å¸‚å¤©æ°”ï¼Œåˆ™locå‚æ•°éœ€è¦è¾“å…¥'Beijing'\", 'type': 'string', 'required': True}}}}]}, {'role': 'user', 'content': 'åŒ—äº¬ä»Šå¤©çš„å¤©æ°”'}, {'role': 'assistant', 'metadata': 'get_weather', 'content': \" ```python\\ntool_call(loc='Beijing')\\n```\"}]\n"
     ]
    }
   ],
   "source": [
    "## æµ‹è¯•ä¸€ä¸‹ï¼Œæ·»åŠ äº†functionä»¥åæ¨¡å‹è°ƒç”¨çš„æ•ˆæœ\n",
    "history = [system_info]\n",
    "query = \"åŒ—äº¬ä»Šå¤©çš„å¤©æ°”\"\n",
    "function_call, history = model.chat(tokenizer, query, history=history)\n",
    "## è¯†åˆ«å‡ºæ¥å»è°ƒç”¨å¦‚ä¸‹çš„å‡½æ•°\n",
    "print(function_call)\n",
    "print(\"==============\")\n",
    "print(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "08fc523f-6cad-4c82-89a6-5dc44e5dfb6f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'get_weather'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## è·å–å‡½æ•°ä¿¡æ¯ï¼Œè·å–åˆ°è¢«è°ƒç”¨å‡½æ•°çš„å‡½æ•°å\n",
    "function_name=function_call[\"name\"]\n",
    "function_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0a9679ed-c53c-4bd1-9288-237a77e6977c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Beijing'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function_call[\"parameters\"][\"loc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3fabfb5a-61e9-4624-b0f0-bba38c7777b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## å¾€å‡½æ•°é‡Œé¢æ·»åŠ å‡½æ•°çš„å®ç°ï¼ˆçœŸæ­£é€»è¾‘çš„å®ç°ï¼Œå»è®¿é—®è·å–å¤©æ°”çš„ä»£ç ï¼‰\n",
    "functions_list = [get_weather]\n",
    "available_functions = {func.__name__: func for func in functions_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "01bd0199-7e77-44f7-be62-5a11516c4780",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.get_weather(loc)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuction_to_call = available_functions[function_name]\n",
    "fuction_to_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b15e257f-5088-426c-b68b-36dbd025918f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loc': 'Beijing'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# è·å–å‡½æ•°å‚æ•°\n",
    "function_args = function_call['parameters']\n",
    "function_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5961fe75-09c7-4fdc-b5f1-4566a7095b48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "function_response = fuction_to_call(**function_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "09661826-db42-416f-97e3-a8626a4eac3f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"coord\": {\"lon\": 116.3972, \"lat\": 39.9075}, \"weather\": [{\"id\": 801, \"main\": \"Clouds\", \"description\": \"\\\\u6674\\\\uff0c\\\\u5c11\\\\u4e91\", \"icon\": \"02d\"}], \"base\": \"stations\", \"main\": {\"temp\": 15.94, \"feels_like\": 14.09, \"temp_min\": 15.94, \"temp_max\": 15.94, \"pressure\": 1011, \"humidity\": 19, \"sea_level\": 1011, \"grnd_level\": 1005}, \"visibility\": 10000, \"wind\": {\"speed\": 4.98, \"deg\": 299, \"gust\": 8.94}, \"clouds\": {\"all\": 12}, \"dt\": 1700634535, \"sys\": {\"type\": 1, \"id\": 9609, \"country\": \"CN\", \"sunrise\": 1700607993, \"sunset\": 1700643269}, \"timezone\": 28800, \"id\": 1816670, \"name\": \"Beijing\", \"cod\": 200}'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "26f02e2a-f81d-41fd-bc48-dd8c09855bbf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## æ·»åŠ è§‚å¯Ÿè€…çš„è§’è‰²ï¼Œname:æ˜¯å‡½æ•°åç§°\n",
    "## contentï¼šè°ƒç”¨å‡½æ•°çš„ä¿¡æ¯\n",
    "# user\n",
    "# system\n",
    "# assistant\n",
    "# observation\n",
    "history=[]\n",
    "history.append(\n",
    "    {\n",
    "        \"role\": \"observation\",\n",
    "        \"name\": function_name,\n",
    "        \"content\": function_response,\n",
    "    }\n",
    ")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7405e879-253e-4cbb-ab13-62586a73268f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## æ¨¡å‹è°ƒç”¨\n",
    "query = \"è¯·å¸®æˆ‘æŸ¥è¯¢ä¸€ä¸‹åŒ—äº¬çš„å¤©æ°”\"\n",
    "response, history = model.chat(tokenizer, query, history=history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cb754a83-02ea-4f7d-b891-05c1a4227e9b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "åŒ—äº¬å½“å‰çš„å¤©æ°”æƒ…å†µå¦‚ä¸‹ï¼š\n",
      "\n",
      "- æ¸©åº¦ï¼š15.94â„ƒï¼Œä½“æ„Ÿæ¸©åº¦ï¼š14.09â„ƒ\n",
      "- å¤©æ°”çŠ¶å†µï¼šClouds\n",
      "- æ¹¿åº¦ï¼š19%\n",
      "- æ°”å‹ï¼š1011 hPa\n",
      "- æµ·å¹³é¢é«˜åº¦ï¼š1011 m\n",
      "- é£é€Ÿï¼š4.98 m/s\n",
      "- é£å‘ï¼š299Â°\n",
      "\n",
      "åŒ—äº¬æ‰€åœ¨çš„åœ°ç‚¹æ˜¯stationsï¼Œå½“å‰æ—¶é—´æ˜¯2022å¹´9æœˆ27æ—¥17:08ã€‚\n"
     ]
    }
   ],
   "source": [
    "##æ‰“å°è¿”å›çš„ç»“æœ\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c92aa2b-35b3-49a3-b66c-4c3caa315ec9",
   "metadata": {},
   "source": [
    "### 3.4 å¯ä»¥è‡ªå·±å°è¯•å°è£…ä¸ºå‡½æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9be0574d-a113-47ce-9601-df55f6b19f02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_conv_glm(query,tokenizer, history, model,functions_list=None, functions=None, return_function_call=True):\n",
    "    \"\"\"\n",
    "    èƒ½å¤Ÿè‡ªåŠ¨æ‰§è¡Œå¤–éƒ¨å‡½æ•°è°ƒç”¨çš„Chatå¯¹è¯æ¨¡å‹\n",
    "    :param messages: å¿…è¦å‚æ•°ï¼Œè¾“å…¥åˆ°Chatæ¨¡å‹çš„messageså‚æ•°å¯¹è±¡\n",
    "    :param functions_list: å¯é€‰å‚æ•°ï¼Œé»˜è®¤ä¸ºNoneï¼Œå¯ä»¥è®¾ç½®ä¸ºåŒ…å«å…¨éƒ¨å¤–éƒ¨å‡½æ•°çš„åˆ—è¡¨å¯¹è±¡\n",
    "    :param model: Chatæ¨¡å‹ï¼Œå¯é€‰å‚æ•°ï¼Œé»˜è®¤æ¨¡å‹ä¸ºchatglm3-6b\n",
    "    :returnï¼šChatæ¨¡å‹è¾“å‡ºç»“æœ\n",
    "    \"\"\"\n",
    "\n",
    "    # å¦‚æœæ²¡æœ‰å¤–éƒ¨å‡½æ•°åº“ï¼Œåˆ™æ‰§è¡Œæ™®é€šçš„å¯¹è¯ä»»åŠ¡\n",
    "    if functions_list == None:\n",
    "        response, history = model.chat(tokenizer, query, history=history)\n",
    "        final_response = response\n",
    "        \n",
    "    # è‹¥å­˜åœ¨å¤–éƒ¨å‡½æ•°åº“ï¼Œåˆ™éœ€è¦çµæ´»é€‰å–å¤–éƒ¨å‡½æ•°å¹¶è¿›è¡Œå›ç­”\n",
    "    else:\n",
    "        # åˆ›å»ºè°ƒç”¨å¤–éƒ¨å‡½æ•°çš„system_message\n",
    "        system_info = {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"Answer the following questions as best as you can. You have access to the following tools:\",\n",
    "            \"tools\": functions,\n",
    "        }\n",
    "        # åˆ›å»ºå¤–éƒ¨å‡½æ•°åº“å­—å…¸\n",
    "        available_functions = {func.__name__: func for func in functions_list}\n",
    "        history=[system_info]\n",
    "        ## ç¬¬ä¸€æ¬¡è°ƒç”¨ï¼Œç›®çš„æ˜¯è·å–å‡½æ•°ä¿¡æ¯\n",
    "        response,history = model.chat(tokenizer, query, history=history)\n",
    "        # éœ€è¦è°ƒç”¨å¤–éƒ¨å‡½æ•°\n",
    "        function_call = response\n",
    "        # è·å–å‡½æ•°å\n",
    "        function_name = function_call[\"name\"]\n",
    "        # è·å–å‡½æ•°å¯¹è±¡\n",
    "        fuction_to_call = available_functions[function_name]\n",
    "        # è·å–å‡½æ•°å‚æ•°\n",
    "        function_args = function_call['parameters']\n",
    "        # å°†å‡½æ•°å‚æ•°è¾“å…¥åˆ°å‡½æ•°ä¸­ï¼Œè·å–å‡½æ•°è®¡ç®—ç»“æœ\n",
    "        function_response = fuction_to_call(**function_args)\n",
    "        ## ç¬¬äºŒæ¬¡è°ƒç”¨ï¼Œå¸¦å…¥è¿›å»å‡½æ•°\n",
    "        # role=\"observation\" è¡¨ç¤ºè¾“å…¥çš„æ˜¯å·¥å…·è°ƒç”¨çš„è¿”å›å€¼è€Œä¸æ˜¯ç”¨æˆ·è¾“å…¥\n",
    "        # role:user,system,assistant,observation\n",
    "        #\n",
    "        #\n",
    "        print(function_response)\n",
    "        history=[]\n",
    "        history.append(\n",
    "                {\n",
    "                    \"role\": \"observation\",\n",
    "                    \"name\": function_name,\n",
    "                    \"content\": function_response,\n",
    "                }\n",
    "        )  \n",
    "        response, history = model.chat(tokenizer, query, history=history)\n",
    "        final_response=response\n",
    "    \n",
    "    return final_response,history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a668a144-d8d0-4abc-a4fe-6b296f81d031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"THUDM/chatglm3-6b\",\n",
    "# trust_remote_code=True)\n",
    "\n",
    "# model = AutoModel.from_pretrained(\"THUDM/chatglm3-6b\",trust_remote_code=True).quantize(4).cuda()\n",
    "\n",
    "# model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5c72dab5-39ac-4d04-9f65-0a605fb7f1bb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"coord\": {\"lon\": 116.3972, \"lat\": 39.9075}, \"weather\": [{\"id\": 801, \"main\": \"Clouds\", \"description\": \"\\u6674\\uff0c\\u5c11\\u4e91\", \"icon\": \"02d\"}], \"base\": \"stations\", \"main\": {\"temp\": 15.94, \"feels_like\": 14.09, \"temp_min\": 15.94, \"temp_max\": 15.94, \"pressure\": 1011, \"humidity\": 19, \"sea_level\": 1011, \"grnd_level\": 1005}, \"visibility\": 10000, \"wind\": {\"speed\": 4.98, \"deg\": 299, \"gust\": 8.94}, \"clouds\": {\"all\": 12}, \"dt\": 1700634535, \"sys\": {\"type\": 1, \"id\": 9609, \"country\": \"CN\", \"sunrise\": 1700607993, \"sunset\": 1700643269}, \"timezone\": 28800, \"id\": 1816670, \"name\": \"Beijing\", \"cod\": 200}\n",
      "åŒ—äº¬ç°åœ¨çš„å¤©æ°”æ˜¯ï¼šCloudsï¼Œæ¸©åº¦ä¸º15.94â„ƒï¼Œæ¹¿åº¦ä¸º19%ã€‚\n"
     ]
    }
   ],
   "source": [
    "query = \"è¯·å¸®æˆ‘æŸ¥è¯¢ä¸€ä¸‹åŒ—äº¬çš„å¤©æ°”\"\n",
    "history=[]\n",
    "functions_list = [get_weather]\n",
    "functions=weather_api_spec\n",
    "\n",
    "response,history = run_conv_glm(query=query,functions=functions,model=model,functions_list=functions_list,history=history,tokenizer=tokenizer)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03705a51-c618-4d3a-86b9-924705e61c30",
   "metadata": {},
   "source": [
    "## 4. æ™ºèƒ½SQLå¹³å°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af957e42-39f8-4858-b15f-17bbede40cec",
   "metadata": {},
   "source": [
    "### 4.1 æ•°æ®åº“å‡†å¤‡ "
   ]
  },
  {
   "cell_type": "raw",
   "id": "94a81afe-6063-4a33-898f-4ba5fff0a9d2",
   "metadata": {},
   "source": [
    "æ­¥éª¤1ï¼šå®‰è£…MySQLæ•°æ®åº“\n",
    "sudo apt-get update\n",
    "sudo apt-get install mysql-server\n",
    "sudo service mysql start\n",
    "sudo systemctl start mysqld\n",
    "æ­¥éª¤2ï¼šåˆ›å»ºæ•°æ®åº“ç”¨æˆ·\n",
    "CREATE USER 'glm'@'localhost' IDENTIFIED BY 'glm';\n",
    "æ­¥éª¤3ï¼šç»™æ•°æ®åº“ç”¨æˆ·èµ‹æƒé™\n",
    "GRANT ALL PRIVILEGES ON *.* TO 'glm'@'localhost';\n",
    "FLUSH PRIVILEGES;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579a3668-b653-40ed-a7ff-0c31a0c1b278",
   "metadata": {},
   "outputs": [],
   "source": [
    "CREATE TABLE user_info (\n",
    "customerID VARCHAR(255),\n",
    "gender VARCHAR(255),\n",
    "SeniorCitizen INT,\n",
    "Partner VARCHAR(255),\n",
    "Dependents VARCHAR(255)\n",
    ");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e955d7bf-d93a-4c26-842f-acad0a0fcd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "INSERT INTO user_info (customerID, gender, SeniorCitizen, Partner, Dependents)\n",
    "VALUES\n",
    "('1', 'Female', 0, 'Yes', 'No'),\n",
    "('2', 'Male', 1, 'No', 'Yes'),\n",
    "('3', 'Male', 0, 'No', 'No'),\n",
    "('4', 'Female', 1, 'Yes', 'Yes'),\n",
    "('5', 'Male', 0, 'No', 'No'),\n",
    "('6', 'Female', 0, 'Yes', 'Yes'),\n",
    "('7', 'Male', 1, 'Yes', 'No'),\n",
    "('8', 'Female', 0, 'No', 'No'),\n",
    "('9', 'Male', 1, 'Yes', 'Yes'),\n",
    "('10', 'Female', 0, 'No', 'No'),\n",
    "('11', 'Male', 0, 'Yes', 'Yes'),\n",
    "('12', 'Female', 1, 'No', 'No'),\n",
    "('13', 'Male', 0, 'No', 'Yes'),\n",
    "('14', 'Female', 0, 'Yes', 'No'),\n",
    "('15', 'Male', 1, 'Yes', 'Yes'),\n",
    "('16', 'Female', 0, 'No', 'No'),\n",
    "('17', 'Male', 0, 'No', 'Yes'),\n",
    "('18', 'Female', 1, 'Yes', 'No'),\n",
    "('19', 'Male', 0, 'No', 'No'),\n",
    "('20', 'Female', 1, 'No', 'Yes');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b16e86-b96d-4999-bf21-ed76658b30ea",
   "metadata": {},
   "source": [
    "### 4.2 SQLæ‰§è¡Œä»£ç å°è£…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "268638d3-bf2c-450e-bbdb-9c9b5926fbdd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple\n",
      "Collecting pymysql\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/e5/30/20467e39523d0cfc2b6227902d3687a16364307260c75e6a1cb4422b0c62/PyMySQL-1.1.0-py3-none-any.whl (44 kB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44 kB 872 kB/s eta 0:00:01\n",
      "\u001B[?25hInstalling collected packages: pymysql\n",
      "Successfully installed pymysql-1.1.0\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "46fa62c1-3b21-443d-a857-0da67ac812e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pymysql\n",
    "import json\n",
    "def sql_inter(sql_query):\n",
    "    \"\"\"\n",
    "    ç”¨äºæ‰§è¡Œä¸€æ®µSQLä»£ç ï¼Œå¹¶æœ€ç»ˆè·å–SQLä»£ç æ‰§è¡Œç»“æœï¼Œ\\\n",
    "    æ ¸å¿ƒåŠŸèƒ½æ˜¯å°†è¾“å…¥çš„SQLä»£ç ä¼ è¾“è‡³MySQLç¯å¢ƒä¸­è¿›è¡Œè¿è¡Œï¼Œ\\\n",
    "    å¹¶æœ€ç»ˆè¿”å›SQLä»£ç è¿è¡Œç»“æœã€‚éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œæœ¬å‡½æ•°æ˜¯å€ŸåŠ©pymysqlæ¥è¿æ¥MySQLæ•°æ®åº“ã€‚\n",
    "    :param sql_query: å­—ç¬¦ä¸²å½¢å¼çš„SQLæŸ¥è¯¢è¯­å¥ï¼Œç”¨äºæ‰§è¡Œå¯¹MySQLä¸­telco_dbæ•°æ®åº“ä¸­å„å¼ è¡¨è¿›è¡ŒæŸ¥è¯¢ï¼Œå¹¶è·å¾—å„è¡¨ä¸­çš„å„ç±»ç›¸å…³ä¿¡æ¯\n",
    "    :returnï¼šsql_queryåœ¨MySQLä¸­çš„è¿è¡Œç»“æœã€‚\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    connection = pymysql.connect(\n",
    "            host=\"localhost\",  # æ•°æ®åº“åœ°å€\n",
    "            user='glm',  # æ•°æ®åº“ç”¨æˆ·å\n",
    "            passwd=\"glm\",  # æ•°æ®åº“å¯†ç \n",
    "            db='chatglm_db',  # æ•°æ®åº“å\n",
    "            charset='utf8'  # å­—ç¬¦é›†é€‰æ‹©utf8\n",
    "        )\n",
    "    \n",
    "    try:\n",
    "        with connection.cursor() as cursor:\n",
    "            # SQLæŸ¥è¯¢è¯­å¥\n",
    "            sql = sql_query\n",
    "            cursor.execute(sql)\n",
    "\n",
    "            # è·å–æŸ¥è¯¢ç»“æœ\n",
    "            results = cursor.fetchall()\n",
    "\n",
    "    finally:\n",
    "        connection.close()\n",
    "    \n",
    "    \n",
    "    return json.dumps(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1bd9a8c5-d209-4c7a-b0fa-a4c9b4fdd09a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[[20]]'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_inter(\"select count(*) from user_info\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58c4608-73bb-4208-a8aa-7b855bff8974",
   "metadata": {},
   "source": [
    "### 4.3 function callå‡½æ•°å°è£…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e6602d8e-56dd-4b32-b221-152526e151ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sql_inter_function_info = [\n",
    "    {\n",
    "    'name': 'sql_inter',\n",
    "    'description': 'ç”¨äºæ‰§è¡Œä¸€æ®µSQLä»£ç ï¼Œå¹¶æœ€ç»ˆè·å–SQLä»£ç æ‰§è¡Œç»“æœï¼Œæ ¸å¿ƒåŠŸèƒ½æ˜¯å°†è¾“å…¥çš„SQLä»£ç ä¼ è¾“è‡³MySQLç¯å¢ƒä¸­è¿›è¡Œè¿è¡Œï¼Œå¹¶æœ€ç»ˆè¿”å›SQLä»£ç è¿è¡Œç»“æœã€‚',\n",
    "    'parameters': {\n",
    "        'type': 'object',\n",
    "        'properties': {\n",
    "            'sql_query': {\n",
    "                'type': 'string',\n",
    "                'description': 'å­—ç¬¦ä¸²å½¢å¼çš„SQLä»£ç ï¼Œå¯ä»¥åœ¨MySQLä¸­è¿è¡Œï¼Œå¹¶è·å–è¿è¡Œç»“æœ'\n",
    "            }\n",
    "        },\n",
    "        'required': ['sql_query']\n",
    "    }\n",
    "}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31fab2a-0d26-414d-8aaa-514167716364",
   "metadata": {},
   "source": [
    "### 4.4 è¯»å–æœ¬åœ°çŸ¥è¯†åº“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2f76bfe9-d302-447c-93da-9710406d7cb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# æ‰“å¼€å¹¶è¯»å–Markdownæ–‡ä»¶\n",
    "with open('user_info.md', 'r', encoding='utf-8') as f:\n",
    "    data_dictionary = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7c8baa5f-2152-443c-862a-8874710a2c00",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[[20]]'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## æ•°æ®åº“æµ‹è¯•\n",
    "sql_inter(sql_query='SELECT COUNT(*) FROM user_info;')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0343f599-1ea4-45c8-b9c8-42600281a66e",
   "metadata": {},
   "source": [
    "### 4.5 å‡½æ•°å°è£… "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "37f1161b-70b6-406f-ad89-de560b44af78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_conv_glm(query,tokenizer, history, model,functions_list=None, functions=None, return_function_call=True):\n",
    "    \"\"\"\n",
    "    èƒ½å¤Ÿè‡ªåŠ¨æ‰§è¡Œå¤–éƒ¨å‡½æ•°è°ƒç”¨çš„Chatå¯¹è¯æ¨¡å‹\n",
    "    :param messages: å¿…è¦å‚æ•°ï¼Œè¾“å…¥åˆ°Chatæ¨¡å‹çš„messageså‚æ•°å¯¹è±¡\n",
    "    :param functions_list: å¯é€‰å‚æ•°ï¼Œé»˜è®¤ä¸ºNoneï¼Œå¯ä»¥è®¾ç½®ä¸ºåŒ…å«å…¨éƒ¨å¤–éƒ¨å‡½æ•°çš„åˆ—è¡¨å¯¹è±¡\n",
    "    :param model: Chatæ¨¡å‹ï¼Œå¯é€‰å‚æ•°ï¼Œé»˜è®¤æ¨¡å‹ä¸ºchatglm3-6b\n",
    "    :returnï¼šChatæ¨¡å‹è¾“å‡ºç»“æœ\n",
    "    \"\"\"\n",
    "\n",
    "    # å¦‚æœæ²¡æœ‰å¤–éƒ¨å‡½æ•°åº“ï¼Œåˆ™æ‰§è¡Œæ™®é€šçš„å¯¹è¯ä»»åŠ¡\n",
    "    if functions_list == None:\n",
    "        response, history = model.chat(tokenizer, query, history=history)\n",
    "        final_response = response\n",
    "        \n",
    "    # è‹¥å­˜åœ¨å¤–éƒ¨å‡½æ•°åº“ï¼Œåˆ™éœ€è¦çµæ´»é€‰å–å¤–éƒ¨å‡½æ•°å¹¶è¿›è¡Œå›ç­”\n",
    "    else:\n",
    "        # åˆ›å»ºè°ƒç”¨å¤–éƒ¨å‡½æ•°çš„system_message\n",
    "        system_info = {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"Answer the following questions as best as you can. You have access to the following tools:\",\n",
    "            \"tools\": functions,\n",
    "        }\n",
    "        # åˆ›å»ºå¤–éƒ¨å‡½æ•°åº“å­—å…¸\n",
    "        available_functions = {func.__name__: func for func in functions_list}\n",
    "        history=[system_info]\n",
    "        ## ç¬¬ä¸€æ¬¡è°ƒç”¨ï¼Œç›®çš„æ˜¯è·å–å‡½æ•°ä¿¡æ¯\n",
    "       \n",
    "        response,history = model.chat(tokenizer, query, history=history)\n",
    "        print(response)\n",
    "        # éœ€è¦è°ƒç”¨å¤–éƒ¨å‡½æ•°\n",
    "        function_call = response\n",
    "        # è·å–å‡½æ•°å\n",
    "        function_name = function_call[\"name\"]\n",
    "        # è·å–å‡½æ•°å¯¹è±¡\n",
    "        fuction_to_call = available_functions[function_name]\n",
    "        # è·å–å‡½æ•°å‚æ•°\n",
    "        function_args = function_call['parameters']\n",
    "        # å°†å‡½æ•°å‚æ•°è¾“å…¥åˆ°å‡½æ•°ä¸­ï¼Œè·å–å‡½æ•°è®¡ç®—ç»“æœ\n",
    "        function_response = fuction_to_call(**function_args)\n",
    "        # print(\"ç­”æ¡ˆ\")\n",
    "        # print(function_response)\n",
    "        # ## ç¬¬äºŒæ¬¡è°ƒç”¨ï¼Œå¸¦å…¥è¿›å»å‡½æ•°\n",
    "        # history=[]\n",
    "        # history.append(\n",
    "        #         {\n",
    "        #             \"role\": \"observation\",\n",
    "        #             \"name\": function_name,\n",
    "        #             \"content\":function_response,\n",
    "        #         }\n",
    "        # ) \n",
    "        # print(history)\n",
    "        # query= \"è¯·å¸®æˆ‘åˆ°æŸ¥è¯¢ä¸€ä¸‹æœ‰å¤šå°‘ç”µä¿¡ç”¨æˆ·ï¼Œå¹¶ç»™å‡ºç­”æ¡ˆ\"\n",
    "        # response, history = model.chat(tokenizer, query, history=history)\n",
    "        final_response=function_response\n",
    "    \n",
    "    return final_response,history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9264b0da-32d7-411a-9906-4c1775e8f1e3",
   "metadata": {},
   "source": [
    "### 4.6 SQLè°ƒç”¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004dcb7f-c5b2-4dae-9375-bf4010d366c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"THUDM/chatglm3-6b\",\n",
    "# trust_remote_code=True)\n",
    "\n",
    "# model = AutoModel.from_pretrained(\"THUDM/chatglm3-6b\",trust_remote_code=True).quantize(4).cuda()\n",
    "\n",
    "# model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6cd748ac-eb47-42ee-8f56-87a616761e44",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'sql_inter', 'parameters': {'sql_query': 'SELECT COUNT(*) FROM user_info'}}\n"
     ]
    }
   ],
   "source": [
    "query = data_dictionary + \",è¯·å¸®æˆ‘åˆ°æŸ¥è¯¢ä¸€ä¸‹æœ‰å¤šå°‘ç”µä¿¡ç”¨æˆ·ï¼Œå¹¶ç»™å‡ºç­”æ¡ˆï¼Ÿ\"\n",
    "history=[]\n",
    "functions_list = [sql_inter]\n",
    "functions=sql_inter_function_info\n",
    "response,history = run_conv_glm(query=query,functions=functions,model=model,functions_list=functions_list,history=history,tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1d1a8624-5201-4d50-8295-d55c2631d48f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[20]]\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37748069-8ddc-4f61-9758-901020e8f786",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

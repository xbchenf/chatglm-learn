{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd7b04dc-3f41-40fb-8f0c-efa547405ead",
   "metadata": {},
   "source": [
    "# ChatGLM大模型开发"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "开发调试说明：本地GPU不足，没有部署ChatGLM,采用下面两种方式进行开发调试\n",
    "1.直接在云服务器中运行Jupyter进行开发测试。\n",
    "2.本地Pycharm连接远程服务器,实现远程服务器本地调试。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "fc6577da-e4f0-4e0e-b7bd-84294e40dc58",
   "metadata": {},
   "source": [
    "## 1. ChatGLM3-6B模型API调用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22003a6-7bbe-4a2f-9b15-c9b57b744ad6",
   "metadata": {},
   "source": [
    "步骤1： 导入相关的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d52d8a5-a5b4-4c64-b9a9-7d6b39ad766a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f03fb3-9ac5-499e-a43b-eb0dce9fa2ba",
   "metadata": {},
   "source": [
    "步骤2：加载tokenizer，首次加载需要的时间较长\n",
    "使用 AutoTokenizer.from_pretrained 方法，加载预训练的tokenizer \"THUDM/chatglm3-6b\" 。\n",
    "trust_remote_code=True 表示信任远程代码。\n",
    "\n",
    "使用Hugging Face上开源的预训练模型，不依赖于chatglm3工程源代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31124224-467f-4782-892e-77480e40fc74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"THUDM/chatglm3-6b\",\n",
    "trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdf7c57-a78b-4385-8bad-3263ee4a7a3a",
   "metadata": {},
   "source": [
    "步骤3：加载预训练模型\n",
    "（这里是直接使用Hugging Face的模型库中开源的预训练模型进行开发测试）\n",
    "使用 AutoModel.from_pretrained 方法，加载预训练的模型 \"THUDM/chatglm3-6b\" 到CUDA设\n",
    "备上。 trust_remote_code=True 表示信任远程代码（如果有）， device='cuda' 表示将模型加载到CUDA设备上以便使用GPU加速\n",
    "\n",
    "要注意的是，根据显卡显存的不同，需要考虑加载不同精度的模型。13GB显存以上的显卡可以直接按照上述代码加载全精度的模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7f0f70-b8ed-4b4a-807f-94a280c220b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModel.from_pretrained(\"THUDM/chatglm3-6b\", trust_remote_code=True,device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "217b4875-7eec-419c-a98c-91d174ca0505",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008466005325317383,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Loading checkpoint shards",
       "rate": null,
       "total": 7,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25f99cdbc22844b7b81abc53f5745fe6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModel.from_pretrained(\"THUDM/chatglm3-6b\",trust_remote_code=True).quantize(8).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "818a4006-ccf3-4eac-ae6f-47fc1a6f334f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00846552848815918,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Loading checkpoint shards",
       "rate": null,
       "total": 7,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d5f4ea28da8414081a830194a0d30ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'round_up' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mAutoModel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mTHUDM/chatglm3-6b\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43mtrust_remote_code\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mquantize\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m4\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mcuda()\n",
      "File \u001B[0;32m~/.cache/huggingface/modules/transformers_modules/THUDM/chatglm3-6b/e46a14881eae613281abbd266ee918e93a56018f/modeling_chatglm.py:1205\u001B[0m, in \u001B[0;36mChatGLMForConditionalGeneration.quantize\u001B[0;34m(self, bits, empty_init, device, **kwargs)\u001B[0m\n\u001B[1;32m   1201\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mquantized \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m   1203\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mquantization_bit \u001B[38;5;241m=\u001B[39m bits\n\u001B[0;32m-> 1205\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransformer\u001B[38;5;241m.\u001B[39mencoder \u001B[38;5;241m=\u001B[39m \u001B[43mquantize\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransformer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbits\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mempty_init\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mempty_init\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1206\u001B[0m \u001B[43m                                    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1207\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[0;32m~/.cache/huggingface/modules/transformers_modules/THUDM/chatglm3-6b/e46a14881eae613281abbd266ee918e93a56018f/quantization.py:155\u001B[0m, in \u001B[0;36mquantize\u001B[0;34m(model, weight_bit_width, empty_init, device)\u001B[0m\n\u001B[1;32m    153\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Replace fp16 linear with quantized linear\"\"\"\u001B[39;00m\n\u001B[1;32m    154\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m model\u001B[38;5;241m.\u001B[39mlayers:\n\u001B[0;32m--> 155\u001B[0m     layer\u001B[38;5;241m.\u001B[39mself_attention\u001B[38;5;241m.\u001B[39mquery_key_value \u001B[38;5;241m=\u001B[39m \u001B[43mQuantizedLinear\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    156\u001B[0m \u001B[43m        \u001B[49m\u001B[43mweight_bit_width\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mweight_bit_width\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    157\u001B[0m \u001B[43m        \u001B[49m\u001B[43mweight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlayer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mself_attention\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mquery_key_value\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcuda\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcurrent_device\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    158\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbias\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlayer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mself_attention\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mquery_key_value\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    159\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlayer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mself_attention\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mquery_key_value\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    160\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlayer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mself_attention\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mquery_key_value\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    161\u001B[0m \u001B[43m        \u001B[49m\u001B[43mempty_init\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mempty_init\u001B[49m\n\u001B[1;32m    162\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    163\u001B[0m     layer\u001B[38;5;241m.\u001B[39mself_attention\u001B[38;5;241m.\u001B[39mdense \u001B[38;5;241m=\u001B[39m QuantizedLinear(\n\u001B[1;32m    164\u001B[0m         weight_bit_width\u001B[38;5;241m=\u001B[39mweight_bit_width,\n\u001B[1;32m    165\u001B[0m         weight\u001B[38;5;241m=\u001B[39mlayer\u001B[38;5;241m.\u001B[39mself_attention\u001B[38;5;241m.\u001B[39mdense\u001B[38;5;241m.\u001B[39mweight\u001B[38;5;241m.\u001B[39mto(torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mcurrent_device()),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    169\u001B[0m         empty_init\u001B[38;5;241m=\u001B[39mempty_init\n\u001B[1;32m    170\u001B[0m     )\n\u001B[1;32m    171\u001B[0m     layer\u001B[38;5;241m.\u001B[39mmlp\u001B[38;5;241m.\u001B[39mdense_h_to_4h \u001B[38;5;241m=\u001B[39m QuantizedLinear(\n\u001B[1;32m    172\u001B[0m         weight_bit_width\u001B[38;5;241m=\u001B[39mweight_bit_width,\n\u001B[1;32m    173\u001B[0m         weight\u001B[38;5;241m=\u001B[39mlayer\u001B[38;5;241m.\u001B[39mmlp\u001B[38;5;241m.\u001B[39mdense_h_to_4h\u001B[38;5;241m.\u001B[39mweight\u001B[38;5;241m.\u001B[39mto(torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mcurrent_device()),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    177\u001B[0m         empty_init\u001B[38;5;241m=\u001B[39mempty_init\n\u001B[1;32m    178\u001B[0m     )\n",
      "File \u001B[0;32m~/.cache/huggingface/modules/transformers_modules/THUDM/chatglm3-6b/e46a14881eae613281abbd266ee918e93a56018f/quantization.py:139\u001B[0m, in \u001B[0;36mQuantizedLinear.__init__\u001B[0;34m(self, weight_bit_width, weight, bias, device, dtype, empty_init, *args, **kwargs)\u001B[0m\n\u001B[1;32m    137\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweight \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mround(weight \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweight_scale[:, \u001B[38;5;28;01mNone\u001B[39;00m])\u001B[38;5;241m.\u001B[39mto(torch\u001B[38;5;241m.\u001B[39mint8)\n\u001B[1;32m    138\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m weight_bit_width \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m4\u001B[39m:\n\u001B[0;32m--> 139\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweight \u001B[38;5;241m=\u001B[39m \u001B[43mcompress_int4_weight\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    141\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweight \u001B[38;5;241m=\u001B[39m Parameter(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweight\u001B[38;5;241m.\u001B[39mto(device), requires_grad\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m    142\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweight_scale \u001B[38;5;241m=\u001B[39m Parameter(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweight_scale\u001B[38;5;241m.\u001B[39mto(device), requires_grad\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "File \u001B[0;32m~/.cache/huggingface/modules/transformers_modules/THUDM/chatglm3-6b/e46a14881eae613281abbd266ee918e93a56018f/quantization.py:76\u001B[0m, in \u001B[0;36mcompress_int4_weight\u001B[0;34m(weight)\u001B[0m\n\u001B[1;32m     73\u001B[0m stream \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mcurrent_stream()\n\u001B[1;32m     75\u001B[0m gridDim \u001B[38;5;241m=\u001B[39m (n, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m---> 76\u001B[0m blockDim \u001B[38;5;241m=\u001B[39m (\u001B[38;5;28mmin\u001B[39m(\u001B[43mround_up\u001B[49m(m, \u001B[38;5;241m32\u001B[39m), \u001B[38;5;241m1024\u001B[39m), \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     78\u001B[0m kernels\u001B[38;5;241m.\u001B[39mint4WeightCompression(\n\u001B[1;32m     79\u001B[0m     gridDim,\n\u001B[1;32m     80\u001B[0m     blockDim,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     83\u001B[0m     [ctypes\u001B[38;5;241m.\u001B[39mc_void_p(weight\u001B[38;5;241m.\u001B[39mdata_ptr()), ctypes\u001B[38;5;241m.\u001B[39mc_void_p(out\u001B[38;5;241m.\u001B[39mdata_ptr()), ctypes\u001B[38;5;241m.\u001B[39mc_int32(n), ctypes\u001B[38;5;241m.\u001B[39mc_int32(m)],\n\u001B[1;32m     84\u001B[0m )\n\u001B[1;32m     85\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m out\n",
      "\u001B[0;31mNameError\u001B[0m: name 'round_up' is not defined"
     ]
    }
   ],
   "source": [
    "model = AutoModel.from_pretrained(\"THUDM/chatglm3-6b\",trust_remote_code=True).quantize(4).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130ff1fa-e6de-4fec-8075-f71c8ca131a7",
   "metadata": {},
   "source": [
    "步骤4：实例化模型\n",
    "接下来则需要对模型进行实例化操作，并且设置为评估模式："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8b47ab3-b65a-4299-b622-12299ac67f10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c7dac1-eca5-4ed5-a853-89698a024b71",
   "metadata": {},
   "source": [
    "步骤5：调用模型并获取结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61cdb9f1-6c47-410c-9aa6-538fd81e717f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好👋！我是人工智能助手 ChatGLM3-6B，很高兴见到你，欢迎问我任何问题。\n"
     ]
    }
   ],
   "source": [
    "response, history = model.chat(tokenizer, \"你好\", history=[])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6225401c-9223-4aa7-955d-ae613d12b52d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'user', 'content': '你好'}, {'role': 'assistant', 'metadata': '', 'content': '你好👋！我是人工智能助手 ChatGLM3-6B，很高兴见到你，欢迎问我任何问题。'}]\n"
     ]
    }
   ],
   "source": [
    "print(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3219d9ba-2766-4f7a-9fea-4bf0d521cd11",
   "metadata": {},
   "source": [
    "如果有多张 GPU，但是每张 GPU 的显存大小都不足以容纳完整的模型，那么可以将模型切分在多张GPU上。首先安装 accelerate: pip install accelerate，\n",
    "然后通过如下方法加载模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707e2149-8995-4cbb-a34f-994350e4659a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_model_on_gpus\n",
    "model = load_model_on_gpus(\"THUDM/chatglm3-6b\", num_gpus=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff16b83a-0fe0-4a5a-9977-75644ff3478e",
   "metadata": {},
   "source": [
    "## 2. OpenAI风格代码调用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a59993-785f-4b6a-ae1e-9a8bdeba75cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ba6b59-32c6-455d-819c-93f74b9af2db",
   "metadata": {},
   "source": [
    "OpenAI风格代码调用，首先启动 python openai_api.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc3f809e-72c3-4ad3-b66a-f8bfccf0ed72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## OpenAI风格代码调用，首先启动 python openai_api.py\n",
    "\n",
    "# 使用curl命令测试返回\n",
    "# curl -X POST \"http://127.0.0.1:8000/v1/chat/completions\" \\\n",
    "# -H \"Content-Type: application/json\" \\\n",
    "# -d \"{\\\"model\\\": \\\"chatglm3-6b\\\", \\\"messages\\\": [{\\\"role\\\": \\\"system\\\", \\\"content\\\": \\\"You are ChatGLM3, a large language model trained by Zhipu.AI. Follow the user's instructions carefully. Respond using markdown.\\\"}, {\\\"role\\\": \\\"user\\\", \\\"content\\\": \\\"你好，给我讲一个故事，大概100字\\\"}], \\\"stream\\\": false, \\\"max_tokens\\\": 100, \\\"temperature\\\": 0.8, \\\"top_p\\\": 0.8}\"\n",
    "\n",
    "# 使用Python代码测返回\n",
    "import requests\n",
    "import json\n",
    "\n",
    "base_url = \"http://127.0.0.1:8000\" # 本地部署的地址,或者使用你访问模型的API地址\n",
    "\n",
    "def create_chat_completion(model, messages):\n",
    "    data = {\n",
    "        \"model\": model, # 模型名称\n",
    "        \"messages\": messages, # 会话历史\n",
    "        \"max_tokens\": 100, # 最多生成字数\n",
    "        \"temperature\": 0.8, # 温度\n",
    "        \"top_p\": 0.8, # 采样概率\n",
    "    }\n",
    "\n",
    "    response = requests.post(f\"{base_url}/v1/chat/completions\", json=data)\n",
    "    decoded_line = response.json()\n",
    "    content = decoded_line.get(\"choices\", [{}])[0].get(\"message\", \"\").get(\"content\", \"\")\n",
    "    return content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a839e69c-90de-45f2-8671-f5f8b28da100",
   "metadata": {},
   "source": [
    "代码调用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d64ccf47-50c3-49e1-a61f-26be68dfa4bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chat_messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are ChatGLM3, a large language model trained by Zhipu.AI. Follow the user's instructions carefully. Respond using markdown.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"你好，给我讲一个故事，大概100字\"\n",
    "        }\n",
    "    ]\n",
    "content = create_chat_completion(\"chatglm3-6b\", chat_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75494686-5f0b-417d-9e5b-9ccd668b012f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 从前有个叫小明的小男孩，他非常喜欢看动画片。有一天，他在电视上看到一则关于神奇世界的广告，于是激动地告诉了他的妈妈。妈妈带他去了一家图书馆， where他们借了许多关于魔法和奇幻的书籍。小明在阅读这些书籍时，发现了一个名为“小飞侠”的角色，他决定要成为一个勇敢的宇航员，探索未知的星球。从此以后，小明常常想象自己是一个勇敢的宇航员，在太空中\n"
     ]
    }
   ],
   "source": [
    "print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a920bdba-5a49-4751-828a-e7939ad35d18",
   "metadata": {},
   "source": [
    "## 3. function calling功能"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcff716-77b2-4e03-87c9-1c6513ea201f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.1 获取天气API演示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4ca048b-8bdb-40d1-8f97-33d9ddc6844f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#open_weather_key = os.getenv(\"OPENWEATHER_API_KEY\")\n",
    "open_weather_key = \"c6748580ef08742adf7bd05d79dd8e5d\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d262e220-95b5-40d1-a33b-b15b4b65d44e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "def get_weather(loc):\n",
    "    \"\"\"\n",
    "    查询即时天气函数\n",
    "    :param loc: 必要参数，字符串类型，用于表示查询天气的具体城市名称，\\\n",
    "    注意，中国的城市需要用对应城市的英文名称代替，例如如果需要查询北京市天气，则loc参数需要输入'Beijing'；\n",
    "    :return：OpenWeather API查询即时天气的结果，具体URL请求地址为：https://api.openweathermap.org/data/2.5/weather\\\n",
    "    返回结果对象类型为解析之后的JSON格式对象，并用字符串形式进行表示，其中包含了全部重要的天气信息\n",
    "    \"\"\"\n",
    "    # Step 1.构建请求\n",
    "    url = \"https://api.openweathermap.org/data/2.5/weather\"\n",
    "\n",
    "    # Step 2.设置查询参数\n",
    "    params = {\n",
    "        \"q\": loc,               \n",
    "        \"appid\": open_weather_key,    # 输入API key\n",
    "        \"units\": \"metric\",            # 使用摄氏度而不是华氏度\n",
    "        \"lang\":\"zh_cn\"                # 输出语言为简体中文\n",
    "    }\n",
    "\n",
    "    # Step 3.发送GET请求\n",
    "    response = requests.get(url, params=params)\n",
    "    \n",
    "    # Step 4.解析响应\n",
    "    data = response.json()\n",
    "    return json.dumps(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab3da98f-714e-4ced-9cd8-5488447fe592",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data=get_weather(\"BeiJing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "044fdefd-ca1e-4342-b9ef-f9d2ce7651f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"coord\": {\"lon\": 116.3972, \"lat\": 39.9075}, \"weather\": [{\"id\": 801, \"main\": \"Clouds\", \"description\": \"\\\\u6674\\\\uff0c\\\\u5c11\\\\u4e91\", \"icon\": \"02d\"}], \"base\": \"stations\", \"main\": {\"temp\": 15.94, \"feels_like\": 14.09, \"temp_min\": 15.94, \"temp_max\": 15.94, \"pressure\": 1011, \"humidity\": 19, \"sea_level\": 1011, \"grnd_level\": 1005}, \"visibility\": 10000, \"wind\": {\"speed\": 4.98, \"deg\": 299, \"gust\": 8.94}, \"clouds\": {\"all\": 12}, \"dt\": 1700633608, \"sys\": {\"type\": 1, \"id\": 9609, \"country\": \"CN\", \"sunrise\": 1700607993, \"sunset\": 1700643269}, \"timezone\": 28800, \"id\": 1816670, \"name\": \"Beijing\", \"cod\": 200}'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec45df0-77ec-4062-b657-fab26055bc8c",
   "metadata": {},
   "source": [
    "### 3.2 直接跟大模型问天气"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "431154f5-7e16-4d4e-ab26-54a4f8b7f2c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008507251739501953,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Loading checkpoint shards",
       "rate": null,
       "total": 7,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b86de086f1934820b0237879b900c826",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##测试模型\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"THUDM/chatglm3-6b\",\n",
    "trust_remote_code=True)\n",
    "\n",
    "model = AutoModel.from_pretrained(\"THUDM/chatglm3-6b\",trust_remote_code=True).quantize(8).cuda()\n",
    "\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5557b95c-872b-41e4-981b-5638a7c31515",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好！作为一个人工智能助手，我无法实时获取北京的最新天气信息。但你可以查看天气预报或使用天气应用来了解当前的北京天气。\n"
     ]
    }
   ],
   "source": [
    "## 测试模型调用\n",
    "response, history = model.chat(tokenizer, \"你好，北京天气怎么样？\", history=[])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a1dd35-dafa-4d03-8ab6-87adc341918b",
   "metadata": {},
   "source": [
    "### 3.3 一步一步演示function调用流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa6b9009-9af4-4f0d-9fbd-9f66c8e613d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## 定义function 函数\n",
    "weather_api_spec = [\n",
    "    {\n",
    "        'name': 'get_weather',\n",
    "        'description': '查询即时天气函数，根据输入的城市名称，查询对应城市的实时天气',\n",
    "        'parameters': {\n",
    "            'type': 'object',\n",
    "            'properties': {\n",
    "                'loc': {\n",
    "                    'description': \"城市名称，注意，中国的城市需要用对应城市的英文名称代替，例如如果需要查询北京市天气，则loc参数需要输入'Beijing'\",\n",
    "                    'type': 'string',\n",
    "                    'required': True\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "51f8ef19-e0dc-4306-a8db-8ec60ae3628c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## 些system角色的prompt以及添加tools\n",
    "system_info = {\"role\": \"system\", \n",
    "               \"content\": \"Answer the following questions as best as you can. You have access to the following tools:\", \n",
    "               \"tools\": weather_api_spec}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "93949f2d-76d3-4290-804c-1585a703b2fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'get_weather', 'parameters': {'loc': 'Beijing'}}\n",
      "==============\n",
      "[{'role': 'system', 'content': 'Answer the following questions as best as you can. You have access to the following tools:', 'tools': [{'name': 'get_weather', 'description': '查询即时天气函数，根据输入的城市名称，查询对应城市的实时天气', 'parameters': {'type': 'object', 'properties': {'loc': {'description': \"城市名称，注意，中国的城市需要用对应城市的英文名称代替，例如如果需要查询北京市天气，则loc参数需要输入'Beijing'\", 'type': 'string', 'required': True}}}}]}, {'role': 'user', 'content': '北京今天的天气'}, {'role': 'assistant', 'metadata': 'get_weather', 'content': \" ```python\\ntool_call(loc='Beijing')\\n```\"}]\n"
     ]
    }
   ],
   "source": [
    "## 测试一下，添加了function以后模型调用的效果\n",
    "history = [system_info]\n",
    "query = \"北京今天的天气\"\n",
    "function_call, history = model.chat(tokenizer, query, history=history)\n",
    "## 识别出来去调用如下的函数\n",
    "print(function_call)\n",
    "print(\"==============\")\n",
    "print(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "08fc523f-6cad-4c82-89a6-5dc44e5dfb6f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'get_weather'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 获取函数信息，获取到被调用函数的函数名\n",
    "function_name=function_call[\"name\"]\n",
    "function_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0a9679ed-c53c-4bd1-9288-237a77e6977c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Beijing'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function_call[\"parameters\"][\"loc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3fabfb5a-61e9-4624-b0f0-bba38c7777b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## 往函数里面添加函数的实现（真正逻辑的实现，去访问获取天气的代码）\n",
    "functions_list = [get_weather]\n",
    "available_functions = {func.__name__: func for func in functions_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "01bd0199-7e77-44f7-be62-5a11516c4780",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.get_weather(loc)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuction_to_call = available_functions[function_name]\n",
    "fuction_to_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b15e257f-5088-426c-b68b-36dbd025918f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loc': 'Beijing'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 获取函数参数\n",
    "function_args = function_call['parameters']\n",
    "function_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5961fe75-09c7-4fdc-b5f1-4566a7095b48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "function_response = fuction_to_call(**function_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "09661826-db42-416f-97e3-a8626a4eac3f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"coord\": {\"lon\": 116.3972, \"lat\": 39.9075}, \"weather\": [{\"id\": 801, \"main\": \"Clouds\", \"description\": \"\\\\u6674\\\\uff0c\\\\u5c11\\\\u4e91\", \"icon\": \"02d\"}], \"base\": \"stations\", \"main\": {\"temp\": 15.94, \"feels_like\": 14.09, \"temp_min\": 15.94, \"temp_max\": 15.94, \"pressure\": 1011, \"humidity\": 19, \"sea_level\": 1011, \"grnd_level\": 1005}, \"visibility\": 10000, \"wind\": {\"speed\": 4.98, \"deg\": 299, \"gust\": 8.94}, \"clouds\": {\"all\": 12}, \"dt\": 1700634535, \"sys\": {\"type\": 1, \"id\": 9609, \"country\": \"CN\", \"sunrise\": 1700607993, \"sunset\": 1700643269}, \"timezone\": 28800, \"id\": 1816670, \"name\": \"Beijing\", \"cod\": 200}'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "26f02e2a-f81d-41fd-bc48-dd8c09855bbf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## 添加观察者的角色，name:是函数名称\n",
    "## content：调用函数的信息\n",
    "# user\n",
    "# system\n",
    "# assistant\n",
    "# observation\n",
    "history=[]\n",
    "history.append(\n",
    "    {\n",
    "        \"role\": \"observation\",\n",
    "        \"name\": function_name,\n",
    "        \"content\": function_response,\n",
    "    }\n",
    ")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7405e879-253e-4cbb-ab13-62586a73268f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## 模型调用\n",
    "query = \"请帮我查询一下北京的天气\"\n",
    "response, history = model.chat(tokenizer, query, history=history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cb754a83-02ea-4f7d-b891-05c1a4227e9b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "北京当前的天气情况如下：\n",
      "\n",
      "- 温度：15.94℃，体感温度：14.09℃\n",
      "- 天气状况：Clouds\n",
      "- 湿度：19%\n",
      "- 气压：1011 hPa\n",
      "- 海平面高度：1011 m\n",
      "- 风速：4.98 m/s\n",
      "- 风向：299°\n",
      "\n",
      "北京所在的地点是stations，当前时间是2022年9月27日17:08。\n"
     ]
    }
   ],
   "source": [
    "##打印返回的结果\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c92aa2b-35b3-49a3-b66c-4c3caa315ec9",
   "metadata": {},
   "source": [
    "### 3.4 可以自己尝试封装为函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9be0574d-a113-47ce-9601-df55f6b19f02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_conv_glm(query,tokenizer, history, model,functions_list=None, functions=None, return_function_call=True):\n",
    "    \"\"\"\n",
    "    能够自动执行外部函数调用的Chat对话模型\n",
    "    :param messages: 必要参数，输入到Chat模型的messages参数对象\n",
    "    :param functions_list: 可选参数，默认为None，可以设置为包含全部外部函数的列表对象\n",
    "    :param model: Chat模型，可选参数，默认模型为chatglm3-6b\n",
    "    :return：Chat模型输出结果\n",
    "    \"\"\"\n",
    "\n",
    "    # 如果没有外部函数库，则执行普通的对话任务\n",
    "    if functions_list == None:\n",
    "        response, history = model.chat(tokenizer, query, history=history)\n",
    "        final_response = response\n",
    "        \n",
    "    # 若存在外部函数库，则需要灵活选取外部函数并进行回答\n",
    "    else:\n",
    "        # 创建调用外部函数的system_message\n",
    "        system_info = {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"Answer the following questions as best as you can. You have access to the following tools:\",\n",
    "            \"tools\": functions,\n",
    "        }\n",
    "        # 创建外部函数库字典\n",
    "        available_functions = {func.__name__: func for func in functions_list}\n",
    "        history=[system_info]\n",
    "        ## 第一次调用，目的是获取函数信息\n",
    "        response,history = model.chat(tokenizer, query, history=history)\n",
    "        # 需要调用外部函数\n",
    "        function_call = response\n",
    "        # 获取函数名\n",
    "        function_name = function_call[\"name\"]\n",
    "        # 获取函数对象\n",
    "        fuction_to_call = available_functions[function_name]\n",
    "        # 获取函数参数\n",
    "        function_args = function_call['parameters']\n",
    "        # 将函数参数输入到函数中，获取函数计算结果\n",
    "        function_response = fuction_to_call(**function_args)\n",
    "        ## 第二次调用，带入进去函数\n",
    "        # role=\"observation\" 表示输入的是工具调用的返回值而不是用户输入\n",
    "        # role:user,system,assistant,observation\n",
    "        #\n",
    "        #\n",
    "        print(function_response)\n",
    "        history=[]\n",
    "        history.append(\n",
    "                {\n",
    "                    \"role\": \"observation\",\n",
    "                    \"name\": function_name,\n",
    "                    \"content\": function_response,\n",
    "                }\n",
    "        )  \n",
    "        response, history = model.chat(tokenizer, query, history=history)\n",
    "        final_response=response\n",
    "    \n",
    "    return final_response,history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a668a144-d8d0-4abc-a4fe-6b296f81d031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"THUDM/chatglm3-6b\",\n",
    "# trust_remote_code=True)\n",
    "\n",
    "# model = AutoModel.from_pretrained(\"THUDM/chatglm3-6b\",trust_remote_code=True).quantize(4).cuda()\n",
    "\n",
    "# model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5c72dab5-39ac-4d04-9f65-0a605fb7f1bb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"coord\": {\"lon\": 116.3972, \"lat\": 39.9075}, \"weather\": [{\"id\": 801, \"main\": \"Clouds\", \"description\": \"\\u6674\\uff0c\\u5c11\\u4e91\", \"icon\": \"02d\"}], \"base\": \"stations\", \"main\": {\"temp\": 15.94, \"feels_like\": 14.09, \"temp_min\": 15.94, \"temp_max\": 15.94, \"pressure\": 1011, \"humidity\": 19, \"sea_level\": 1011, \"grnd_level\": 1005}, \"visibility\": 10000, \"wind\": {\"speed\": 4.98, \"deg\": 299, \"gust\": 8.94}, \"clouds\": {\"all\": 12}, \"dt\": 1700634535, \"sys\": {\"type\": 1, \"id\": 9609, \"country\": \"CN\", \"sunrise\": 1700607993, \"sunset\": 1700643269}, \"timezone\": 28800, \"id\": 1816670, \"name\": \"Beijing\", \"cod\": 200}\n",
      "北京现在的天气是：Clouds，温度为15.94℃，湿度为19%。\n"
     ]
    }
   ],
   "source": [
    "query = \"请帮我查询一下北京的天气\"\n",
    "history=[]\n",
    "functions_list = [get_weather]\n",
    "functions=weather_api_spec\n",
    "\n",
    "response,history = run_conv_glm(query=query,functions=functions,model=model,functions_list=functions_list,history=history,tokenizer=tokenizer)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03705a51-c618-4d3a-86b9-924705e61c30",
   "metadata": {},
   "source": [
    "## 4. 智能SQL平台"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af957e42-39f8-4858-b15f-17bbede40cec",
   "metadata": {},
   "source": [
    "### 4.1 数据库准备 "
   ]
  },
  {
   "cell_type": "raw",
   "id": "94a81afe-6063-4a33-898f-4ba5fff0a9d2",
   "metadata": {},
   "source": [
    "步骤1：安装MySQL数据库\n",
    "sudo apt-get update\n",
    "sudo apt-get install mysql-server\n",
    "sudo service mysql start\n",
    "sudo systemctl start mysqld\n",
    "步骤2：创建数据库用户\n",
    "CREATE USER 'glm'@'localhost' IDENTIFIED BY 'glm';\n",
    "步骤3：给数据库用户赋权限\n",
    "GRANT ALL PRIVILEGES ON *.* TO 'glm'@'localhost';\n",
    "FLUSH PRIVILEGES;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579a3668-b653-40ed-a7ff-0c31a0c1b278",
   "metadata": {},
   "outputs": [],
   "source": [
    "CREATE TABLE user_info (\n",
    "customerID VARCHAR(255),\n",
    "gender VARCHAR(255),\n",
    "SeniorCitizen INT,\n",
    "Partner VARCHAR(255),\n",
    "Dependents VARCHAR(255)\n",
    ");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e955d7bf-d93a-4c26-842f-acad0a0fcd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "INSERT INTO user_info (customerID, gender, SeniorCitizen, Partner, Dependents)\n",
    "VALUES\n",
    "('1', 'Female', 0, 'Yes', 'No'),\n",
    "('2', 'Male', 1, 'No', 'Yes'),\n",
    "('3', 'Male', 0, 'No', 'No'),\n",
    "('4', 'Female', 1, 'Yes', 'Yes'),\n",
    "('5', 'Male', 0, 'No', 'No'),\n",
    "('6', 'Female', 0, 'Yes', 'Yes'),\n",
    "('7', 'Male', 1, 'Yes', 'No'),\n",
    "('8', 'Female', 0, 'No', 'No'),\n",
    "('9', 'Male', 1, 'Yes', 'Yes'),\n",
    "('10', 'Female', 0, 'No', 'No'),\n",
    "('11', 'Male', 0, 'Yes', 'Yes'),\n",
    "('12', 'Female', 1, 'No', 'No'),\n",
    "('13', 'Male', 0, 'No', 'Yes'),\n",
    "('14', 'Female', 0, 'Yes', 'No'),\n",
    "('15', 'Male', 1, 'Yes', 'Yes'),\n",
    "('16', 'Female', 0, 'No', 'No'),\n",
    "('17', 'Male', 0, 'No', 'Yes'),\n",
    "('18', 'Female', 1, 'Yes', 'No'),\n",
    "('19', 'Male', 0, 'No', 'No'),\n",
    "('20', 'Female', 1, 'No', 'Yes');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b16e86-b96d-4999-bf21-ed76658b30ea",
   "metadata": {},
   "source": [
    "### 4.2 SQL执行代码封装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "268638d3-bf2c-450e-bbdb-9c9b5926fbdd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple\n",
      "Collecting pymysql\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/e5/30/20467e39523d0cfc2b6227902d3687a16364307260c75e6a1cb4422b0c62/PyMySQL-1.1.0-py3-none-any.whl (44 kB)\n",
      "\u001B[K     |████████████████████████████████| 44 kB 872 kB/s eta 0:00:01\n",
      "\u001B[?25hInstalling collected packages: pymysql\n",
      "Successfully installed pymysql-1.1.0\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "46fa62c1-3b21-443d-a857-0da67ac812e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pymysql\n",
    "import json\n",
    "def sql_inter(sql_query):\n",
    "    \"\"\"\n",
    "    用于执行一段SQL代码，并最终获取SQL代码执行结果，\\\n",
    "    核心功能是将输入的SQL代码传输至MySQL环境中进行运行，\\\n",
    "    并最终返回SQL代码运行结果。需要注意的是，本函数是借助pymysql来连接MySQL数据库。\n",
    "    :param sql_query: 字符串形式的SQL查询语句，用于执行对MySQL中telco_db数据库中各张表进行查询，并获得各表中的各类相关信息\n",
    "    :return：sql_query在MySQL中的运行结果。\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    connection = pymysql.connect(\n",
    "            host=\"localhost\",  # 数据库地址\n",
    "            user='glm',  # 数据库用户名\n",
    "            passwd=\"glm\",  # 数据库密码\n",
    "            db='chatglm_db',  # 数据库名\n",
    "            charset='utf8'  # 字符集选择utf8\n",
    "        )\n",
    "    \n",
    "    try:\n",
    "        with connection.cursor() as cursor:\n",
    "            # SQL查询语句\n",
    "            sql = sql_query\n",
    "            cursor.execute(sql)\n",
    "\n",
    "            # 获取查询结果\n",
    "            results = cursor.fetchall()\n",
    "\n",
    "    finally:\n",
    "        connection.close()\n",
    "    \n",
    "    \n",
    "    return json.dumps(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1bd9a8c5-d209-4c7a-b0fa-a4c9b4fdd09a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[[20]]'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_inter(\"select count(*) from user_info\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58c4608-73bb-4208-a8aa-7b855bff8974",
   "metadata": {},
   "source": [
    "### 4.3 function call函数封装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e6602d8e-56dd-4b32-b221-152526e151ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sql_inter_function_info = [\n",
    "    {\n",
    "    'name': 'sql_inter',\n",
    "    'description': '用于执行一段SQL代码，并最终获取SQL代码执行结果，核心功能是将输入的SQL代码传输至MySQL环境中进行运行，并最终返回SQL代码运行结果。',\n",
    "    'parameters': {\n",
    "        'type': 'object',\n",
    "        'properties': {\n",
    "            'sql_query': {\n",
    "                'type': 'string',\n",
    "                'description': '字符串形式的SQL代码，可以在MySQL中运行，并获取运行结果'\n",
    "            }\n",
    "        },\n",
    "        'required': ['sql_query']\n",
    "    }\n",
    "}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31fab2a-0d26-414d-8aaa-514167716364",
   "metadata": {},
   "source": [
    "### 4.4 读取本地知识库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2f76bfe9-d302-447c-93da-9710406d7cb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 打开并读取Markdown文件\n",
    "with open('user_info.md', 'r', encoding='utf-8') as f:\n",
    "    data_dictionary = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7c8baa5f-2152-443c-862a-8874710a2c00",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[[20]]'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 数据库测试\n",
    "sql_inter(sql_query='SELECT COUNT(*) FROM user_info;')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0343f599-1ea4-45c8-b9c8-42600281a66e",
   "metadata": {},
   "source": [
    "### 4.5 函数封装 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "37f1161b-70b6-406f-ad89-de560b44af78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_conv_glm(query,tokenizer, history, model,functions_list=None, functions=None, return_function_call=True):\n",
    "    \"\"\"\n",
    "    能够自动执行外部函数调用的Chat对话模型\n",
    "    :param messages: 必要参数，输入到Chat模型的messages参数对象\n",
    "    :param functions_list: 可选参数，默认为None，可以设置为包含全部外部函数的列表对象\n",
    "    :param model: Chat模型，可选参数，默认模型为chatglm3-6b\n",
    "    :return：Chat模型输出结果\n",
    "    \"\"\"\n",
    "\n",
    "    # 如果没有外部函数库，则执行普通的对话任务\n",
    "    if functions_list == None:\n",
    "        response, history = model.chat(tokenizer, query, history=history)\n",
    "        final_response = response\n",
    "        \n",
    "    # 若存在外部函数库，则需要灵活选取外部函数并进行回答\n",
    "    else:\n",
    "        # 创建调用外部函数的system_message\n",
    "        system_info = {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"Answer the following questions as best as you can. You have access to the following tools:\",\n",
    "            \"tools\": functions,\n",
    "        }\n",
    "        # 创建外部函数库字典\n",
    "        available_functions = {func.__name__: func for func in functions_list}\n",
    "        history=[system_info]\n",
    "        ## 第一次调用，目的是获取函数信息\n",
    "       \n",
    "        response,history = model.chat(tokenizer, query, history=history)\n",
    "        print(response)\n",
    "        # 需要调用外部函数\n",
    "        function_call = response\n",
    "        # 获取函数名\n",
    "        function_name = function_call[\"name\"]\n",
    "        # 获取函数对象\n",
    "        fuction_to_call = available_functions[function_name]\n",
    "        # 获取函数参数\n",
    "        function_args = function_call['parameters']\n",
    "        # 将函数参数输入到函数中，获取函数计算结果\n",
    "        function_response = fuction_to_call(**function_args)\n",
    "        # print(\"答案\")\n",
    "        # print(function_response)\n",
    "        # ## 第二次调用，带入进去函数\n",
    "        # history=[]\n",
    "        # history.append(\n",
    "        #         {\n",
    "        #             \"role\": \"observation\",\n",
    "        #             \"name\": function_name,\n",
    "        #             \"content\":function_response,\n",
    "        #         }\n",
    "        # ) \n",
    "        # print(history)\n",
    "        # query= \"请帮我到查询一下有多少电信用户，并给出答案\"\n",
    "        # response, history = model.chat(tokenizer, query, history=history)\n",
    "        final_response=function_response\n",
    "    \n",
    "    return final_response,history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9264b0da-32d7-411a-9906-4c1775e8f1e3",
   "metadata": {},
   "source": [
    "### 4.6 SQL调用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004dcb7f-c5b2-4dae-9375-bf4010d366c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"THUDM/chatglm3-6b\",\n",
    "# trust_remote_code=True)\n",
    "\n",
    "# model = AutoModel.from_pretrained(\"THUDM/chatglm3-6b\",trust_remote_code=True).quantize(4).cuda()\n",
    "\n",
    "# model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6cd748ac-eb47-42ee-8f56-87a616761e44",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'sql_inter', 'parameters': {'sql_query': 'SELECT COUNT(*) FROM user_info'}}\n"
     ]
    }
   ],
   "source": [
    "query = data_dictionary + \",请帮我到查询一下有多少电信用户，并给出答案？\"\n",
    "history=[]\n",
    "functions_list = [sql_inter]\n",
    "functions=sql_inter_function_info\n",
    "response,history = run_conv_glm(query=query,functions=functions,model=model,functions_list=functions_list,history=history,tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1d1a8624-5201-4d50-8295-d55c2631d48f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[20]]\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37748069-8ddc-4f61-9758-901020e8f786",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
